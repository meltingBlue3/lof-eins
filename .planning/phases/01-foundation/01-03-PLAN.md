---
phase: 01-foundation
plan: 03
type: execute
wave: 2
depends_on:
  - 01-01  # BUG-02 must be complete for schema consistency
files_modified:
  - src/data/downloader.py
  - src/data/generator/generators.py
  - src/data/migrations/002_update_limit_events.py
autonomous: true

must_haves:
  truths:
    - "limit_events.end_date is nullable (no NOT NULL constraint)"
    - "limit_events.has is_open_ended generated/virtual column"
    - "limit_events.has source_announcement_ids field for audit trail"
    - "limit_events.has reason field for human-readable context"
    - "Migration script can update existing databases"
  artifacts:
    - path: "src/data/downloader.py"
      provides: "Updated limit_events schema with new columns"
      pattern: "is_open_ended"
    - path: "src/data/generator/generators.py"
      provides: "Updated schema and population of new fields"
      pattern: "source_announcement_ids"
    - path: "src/data/migrations/002_update_limit_events.py"
      provides: "Migration script for schema updates"
      min_lines: 80
  key_links:
    - from: "is_open_ended column"
      to: "end_date IS NULL"
      via: "SQLite generated column expression"
    - from: "source_announcement_ids"
      to: "announcement_parses.id"
      via: "JSON array of source announcement IDs"
---

<objective>
Update the limit_events table schema with new columns for enhanced functionality.

Purpose: Add computed columns and metadata fields to support open-ended limit detection and audit trails. The is_open_ended column automatically identifies open-ended limits, source_announcement_ids tracks which announcements contributed to an event, and reason provides human-readable context.

Output: Updated schema in downloader.py and generators.py, plus a migration script to update existing databases.
</objective>

<execution_context>
@C:/Users/zhang/.config/opencode/get-shit-done/workflows/execute-plan.md
@C:/Users/zhang/.config/opencode/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/phases/01-foundation/01-01-SUMMARY.md
@.planning/PROJECT.md
@.planning/ROADMAP.md

**Schema Updates Required:**

**limit_events table additions:**
1. Ensure end_date is nullable (already done in Plan 01)
2. Add `is_open_ended` - INTEGER generated column (1 if end_date IS NULL, else 0)
3. Add `source_announcement_ids` - TEXT (JSON array of source announcement IDs)
4. Add `reason` - TEXT (human-readable explanation)

**SQLite Generated Column Syntax:**
```sql
is_open_ended INTEGER GENERATED ALWAYS AS (CASE WHEN end_date IS NULL THEN 1 ELSE 0 END) STORED
```

**Note:** SQLite 3.31.0+ supports generated columns. For older versions, we may need to use triggers or application-level logic.

**Migration Requirements:**
- Add columns to existing tables
- Handle databases that may already have some columns
- Maintain backward compatibility
</context>

<tasks>

<task type="auto">
  <name>Task 1: Update limit_events schema in downloader.py</name>
  <files>src/data/downloader.py</files>
  <action>
    Update the `_generate_limit_db()` method to include the new columns.
    
    Current schema (after Plan 01):
    ```python
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS limit_events (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            ticker TEXT NOT NULL,
            start_date DATE NOT NULL,
            end_date DATE,
            max_amount REAL NOT NULL,
            reason TEXT
        )
    ''')
    ```
    
    Update to:
    ```python
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS limit_events (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            ticker TEXT NOT NULL,
            start_date DATE NOT NULL,
            end_date DATE,
            max_amount REAL NOT NULL,
            is_open_ended INTEGER GENERATED ALWAYS AS (
                CASE WHEN end_date IS NULL THEN 1 ELSE 0 END
            ) STORED,
            source_announcement_ids TEXT,
            reason TEXT
        )
    ''')
    
    # Add index on is_open_ended for efficient filtering
    cursor.execute('''
        CREATE INDEX IF NOT EXISTS idx_limit_events_open_ended 
        ON limit_events(is_open_ended)
    ''')
    ```
    
    Note: source_announcement_ids will store a JSON array like '[1, 2, 3]' referencing announcement_parses.id values.
  </action>
  <verify>
    Verify the CREATE TABLE includes all new columns
  </verify>
  <done>
    - is_open_ended generated column added
    - source_announcement_ids TEXT field added
    - reason field preserved (already existed)
    - Index on is_open_ended created
  </done>
</task>

<task type="auto">
  <name>Task 2: Update limit_events schema in generators.py</name>
  <files>src/data/generator/generators.py</files>
  <action>
    Update the limit_events CREATE TABLE statement to match downloader.py with all new columns.
    
    Current schema (lines 206-215):
    ```python
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS limit_events (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            ticker TEXT NOT NULL,
            start_date DATE NOT NULL,
            end_date DATE,
            max_amount REAL DEFAULT 100.0,
            reason TEXT
        )
    """)
    ```
    
    Update to:
    ```python
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS limit_events (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            ticker TEXT NOT NULL,
            start_date DATE NOT NULL,
            end_date DATE,
            max_amount REAL DEFAULT 100.0,
            is_open_ended INTEGER GENERATED ALWAYS AS (
                CASE WHEN end_date IS NULL THEN 1 ELSE 0 END
            ) STORED,
            source_announcement_ids TEXT,
            reason TEXT
        )
    """)
    ```
    
    Also add the index creation:
    ```python
    cursor.execute("""
        CREATE INDEX IF NOT EXISTS idx_limit_events_open_ended 
        ON limit_events(is_open_ended)
    """)
    ```
    
    Update the INSERT statement (lines 218-228) to include source_announcement_ids. Since mock data doesn't have real announcements, insert NULL or an empty JSON array '[]':
    ```python
    cursor.execute("""
        INSERT INTO limit_events (ticker, start_date, end_date, max_amount, source_announcement_ids, reason)
        VALUES (?, ?, ?, ?, ?, ?)
    """, (
        event['ticker'],
        event['start_date'],
        event['end_date'],
        event['max_amount'],
        '[]',  # Empty JSON array for mock data
        event['reason']
    ))
    ```
  </action>
  <verify>
    Verify CREATE TABLE and INSERT statements are updated
  </verify>
  <done>
    - Schema updated with all new columns
    - Index on is_open_ended created
    - INSERT statement updated to populate source_announcement_ids
  </done>
</task>

<task type="auto">
  <name>Task 3: Create migration script for existing databases</name>
  <files>src/data/migrations/002_update_limit_events.py</files>
  <action>
    Create a migration script that can update existing fund_status.db files to the new schema.
    
    Create the migrations directory first if it doesn't exist, then create the migration file:
    
    ```python
    """
    Migration 002: Update limit_events schema
    
    Adds new columns to support open-ended limits and audit trails:
    - is_open_ended (generated column)
    - source_announcement_ids (JSON text)
    
    Usage:
        python src/data/migrations/002_update_limit_events.py --db path/to/fund_status.db
    """
    
    import sqlite3
    import argparse
    from pathlib import Path
    import sys
    
    def migrate_database(db_path: str) -> bool:
        """Apply schema updates to existing database."""
        db_path = Path(db_path)
        
        if not db_path.exists():
            print(f"[ERROR] Database not found: {db_path}")
            return False
        
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        try:
            # Check current schema
            cursor.execute("PRAGMA table_info(limit_events)")
            existing_columns = {row[1] for row in cursor.fetchall()}
            
            # Add is_open_ended if not exists
            if 'is_open_ended' not in existing_columns:
                print("[MIGRATE] Adding is_open_ended column...")
                cursor.execute('''
                    ALTER TABLE limit_events 
                    ADD COLUMN is_open_ended INTEGER 
                    GENERATED ALWAYS AS (
                        CASE WHEN end_date IS NULL THEN 1 ELSE 0 END
                    ) STORED
                ''')
            else:
                print("[SKIP] is_open_ended column already exists")
            
            # Add source_announcement_ids if not exists
            if 'source_announcement_ids' not in existing_columns:
                print("[MIGRATE] Adding source_announcement_ids column...")
                cursor.execute('''
                    ALTER TABLE limit_events 
                    ADD COLUMN source_announcement_ids TEXT
                ''')
                # Initialize with empty array for existing records
                cursor.execute("""
                    UPDATE limit_events 
                    SET source_announcement_ids = '[]' 
                    WHERE source_announcement_ids IS NULL
                """)
            else:
                print("[SKIP] source_announcement_ids column already exists")
            
            # Create index on is_open_ended if not exists
            cursor.execute("""
                SELECT name FROM sqlite_master 
                WHERE type='index' AND name='idx_limit_events_open_ended'
            """)
            if not cursor.fetchone():
                print("[MIGRATE] Creating index on is_open_ended...")
                cursor.execute('''
                    CREATE INDEX idx_limit_events_open_ended 
                    ON limit_events(is_open_ended)
                ''')
            else:
                print("[SKIP] Index idx_limit_events_open_ended already exists")
            
            conn.commit()
            print(f"[OK] Migration complete: {db_path}")
            return True
            
        except sqlite3.Error as e:
            print(f"[ERROR] Migration failed: {e}")
            conn.rollback()
            return False
        finally:
            conn.close()
    
    def main():
        parser = argparse.ArgumentParser(description='Update limit_events schema')
        parser.add_argument('--db', required=True, help='Path to fund_status.db')
        args = parser.parse_args()
        
        success = migrate_database(args.db)
        sys.exit(0 if success else 1)
    
    if __name__ == '__main__':
        main()
    ```
    
    Note: Some older SQLite versions may not support generated columns in ALTER TABLE. Add a fallback that creates the column as regular INTEGER with a trigger to maintain it, or document the minimum SQLite version requirement (3.31.0+).
  </action>
  <verify>
    Test migration script with: python src/data/migrations/002_update_limit_events.py --db data/mock/config/fund_status.db (if exists)
  </verify>
  <done>
    - Migration script created
    - Handles adding columns if they don't exist
    - Initializes source_announcement_ids with '[]'
    - Creates index on is_open_ended
    - Has proper error handling and rollback
  </done>
</task>

</tasks>

<verification>
After completing all tasks:
1. Run migration script on test database
2. Verify all columns exist with correct types
3. Test is_open_ended is correctly computed for NULL end_dates
</verification>

<success_criteria>
- limit_events schema includes is_open_ended generated column
- source_announcement_ids field exists (TEXT for JSON)
- reason field preserved
- Index on is_open_ended created
- Migration script can update existing databases
- All changes backward compatible
</success_criteria>

<output>
After completion, create `.planning/phases/01-foundation/01-03-SUMMARY.md`
</output>
