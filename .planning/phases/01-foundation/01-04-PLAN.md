---
phase: 01-foundation
plan: 04
type: execute
wave: 3
depends_on:
  - 01-01  # BUG fixes must be complete
  - 01-02  # New tables must exist
  - 01-03  # Schema updates must be complete
files_modified:
  - tests/test_open_ended_limits.py
  - tests/test_database_schema.py
autonomous: true

must_haves:
  truths:
    - "Unit tests verify NULL end_date handling in DataLoader"
    - "Unit tests verify open-ended limits apply correctly to daily series"
    - "Unit tests verify database schema (nullable end_date, new columns)"
    - "All existing tests still pass"
  artifacts:
    - path: "tests/test_open_ended_limits.py"
      provides: "Comprehensive NULL handling tests"
      min_lines: 100
    - path: "tests/test_database_schema.py"
      provides: "Schema validation tests"
      min_lines: 80
  key_links:
    - from: "test_open_ended_limits.py"
      to: "src/data/loader.py"
      via: "tests _resample_limits_to_daily()"
    - from: "test_database_schema.py"
      to: "fund_status.db schema"
      via: "validates table structure"
---

<objective>
Add comprehensive unit tests for NULL handling and database schema.

Purpose: Verify that the bug fixes and schema changes work correctly. Tests must cover edge cases like NULL end_date handling, open-ended limits spanning the entire date range, and schema validation for all three tables.

Output: Two test files with comprehensive coverage, plus verification that all existing tests still pass.
</objective>

<execution_context>
@C:/Users/zhang/.config/opencode/get-shit-done/workflows/execute-plan.md
@C:/Users/zhang/.config/opencode/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/phases/01-foundation/01-01-SUMMARY.md
@.planning/phases/01-foundation/01-02-SUMMARY.md
@.planning/phases/01-foundation/01-03-SUMMARY.md
@tests/test_loader.py

**Test Requirements:**

**test_open_ended_limits.py:**
- Test NULL end_date creates open-ended limit
- Test open-ended limit applies to all dates >= start_date
- Test mixed limits (some with end_date, some without)
- Test DataLoader produces correct daily_limit series
- Test edge case: start_date at beginning of range
- Test edge case: NULL end_date with dates extending beyond data range

**test_database_schema.py:**
- Test limit_events schema (columns, nullability, indexes)
- Test announcement_parses schema
- Test limit_event_log schema
- Test is_open_ended generated column computes correctly
- Test backward compatibility with existing data

**Key test case for NULL handling:**
```python
# Event: start_date='2024-01-15', end_date=NULL
# Should apply to all dates >= 2024-01-15
dates = pd.date_range('2024-01-01', '2024-01-31')
# Expected: daily_limit == max_amount for dates >= '2024-01-15'
# Expected: daily_limit == inf for dates < '2024-01-15'
```
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create comprehensive NULL handling tests</name>
  <files>tests/test_open_ended_limits.py</files>
  <action>
    Create a comprehensive test file for open-ended limit handling.
    
    ```python
    """
    Tests for open-ended limit handling (NULL end_date).
    
    Verifies that DataLoader correctly applies limits with NULL end_date
to all dates >= start_date.
    """
    
    import sys
    from pathlib import Path
    sys.path.insert(0, str(Path(__file__).parent.parent))
    
    import unittest
    import sqlite3
    import tempfile
    import pandas as pd
    import numpy as np
    from datetime import datetime, timedelta
    
    from src.data.loader import DataLoader
    
    
    class TestOpenEndedLimits(unittest.TestCase):
        """Test NULL end_date handling in DataLoader."""
        
        def setUp(self):
            """Create temporary test data."""
            self.temp_dir = tempfile.mkdtemp()
            self.data_dir = Path(self.temp_dir) / 'data' / 'mock'
            self.data_dir.mkdir(parents=True)
            
            # Create subdirectories
            (self.data_dir / 'market').mkdir()
            (self.data_dir / 'nav').mkdir()
            (self.data_dir / 'config').mkdir()
            
            # Generate test dates (20 business days)
            self.dates = pd.bdate_range('2024-01-01', periods=20)
            self.ticker = 'TEST001'
            
            # Create market data
            market_df = pd.DataFrame({
                'date': self.dates,
                'ticker': self.ticker,
                'open': [10.0] * 20,
                'high': [11.0] * 20,
                'low': [9.0] * 20,
                'close': [10.5] * 20,
                'volume': [100000] * 20
            })
            market_df.to_parquet(self.data_dir / 'market' / f'{self.ticker}.parquet', index=False)
            
            # Create NAV data
            nav_df = pd.DataFrame({
                'date': self.dates,
                'ticker': self.ticker,
                'nav': [10.0] * 20
            })
            nav_df.to_parquet(self.data_dir / 'nav' / f'{self.ticker}.parquet', index=False)
            
            # Create fees CSV
            fees_df = pd.DataFrame({
                'ticker': [self.ticker],
                'fee_rate_tier_1': [0.015],
                'fee_limit_1': [500000],
                'fee_rate_tier_2': [0.01],
                'fee_limit_2': [2000000],
                'fee_fixed': [1000],
                'redeem_fee_7d': [0.015]
            })
            fees_df.to_csv(self.data_dir / 'config' / 'fees.csv', index=False)
            
            self.db_path = self.data_dir / 'config' / 'fund_status.db'
        
        def tearDown(self):
            """Clean up temporary data."""
            import shutil
            shutil.rmtree(self.temp_dir)
        
        def _create_limit_events(self, events):
            """Helper to create limit_events table with given events."""
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS limit_events (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    ticker TEXT NOT NULL,
                    start_date DATE NOT NULL,
                    end_date DATE,
                    max_amount REAL NOT NULL,
                    reason TEXT
                )
            ''')
            
            for event in events:
                cursor.execute('''
                    INSERT INTO limit_events (ticker, start_date, end_date, max_amount, reason)
                    VALUES (?, ?, ?, ?, ?)
                ''', (
                    event.get('ticker', self.ticker),
                    event['start_date'],
                    event.get('end_date'),
                    event['max_amount'],
                    event.get('reason', 'Test')
                ))
            
            conn.commit()
            conn.close()
        
        def test_null_end_date_applies_to_all_future_dates(self):
            """Test that NULL end_date applies limit to all dates >= start_date."""
            # Create open-ended limit starting from day 10
            start_date = self.dates[9].strftime('%Y-%m-%d')
            self._create_limit_events([{
                'start_date': start_date,
                'end_date': None,  # NULL / open-ended
                'max_amount': 100.0,
                'reason': 'Open-ended test'
            }])
            
            # Load data
            loader = DataLoader(str(self.data_dir))
            df = loader.load_bundle(self.ticker)
            
            # Verify: dates before start_date should have inf limit
            for i in range(9):
                date_str = self.dates[i].strftime('%Y-%m-%d')
                if date_str in df.index:
                    self.assertEqual(
                        df.loc[date_str, 'daily_limit'],
                        float('inf'),
                        f"Date {date_str} before start should have no limit"
                    )
            
            # Verify: dates on and after start_date should have limit
            for i in range(9, len(self.dates)):
                date_str = self.dates[i].strftime('%Y-%m-%d')
                if date_str in df.index:
                    self.assertEqual(
                        df.loc[date_str, 'daily_limit'],
                        100.0,
                        f"Date {date_str} on/after start should have limit"
                    )
        
        def test_closed_limit_with_end_date(self):
            """Test that limits with end_date only apply within range."""
            # Create closed limit from day 5 to day 10
            self._create_limit_events([{
                'start_date': self.dates[4].strftime('%Y-%m-%d'),
                'end_date': self.dates[9].strftime('%Y-%m-%d'),
                'max_amount': 500.0,
                'reason': 'Closed limit test'
            }])
            
            loader = DataLoader(str(self.data_dir))
            df = loader.load_bundle(self.ticker)
            
            # Before limit: should be inf
            for i in range(4):
                date_str = self.dates[i].strftime('%Y-%m-%d')
                if date_str in df.index:
                    self.assertEqual(df.loc[date_str, 'daily_limit'], float('inf'))
            
            # During limit: should be 500
            for i in range(4, 10):
                date_str = self.dates[i].strftime('%Y-%m-%d')
                if date_str in df.index:
                    self.assertEqual(df.loc[date_str, 'daily_limit'], 500.0)
            
            # After limit: should be inf
            for i in range(10, len(self.dates)):
                date_str = self.dates[i].strftime('%Y-%m-%d')
                if date_str in df.index:
                    self.assertEqual(df.loc[date_str, 'daily_limit'], float('inf'))
        
        def test_mixed_open_and_closed_limits(self):
            """Test multiple limits where one is open-ended."""
            self._create_limit_events([
                {
                    'start_date': self.dates[4].strftime('%Y-%m-%d'),
                    'end_date': self.dates[9].strftime('%Y-%m-%d'),
                    'max_amount': 500.0,
                    'reason': 'First limit (closed)'
                },
                {
                    'start_date': self.dates[14].strftime('%Y-%m-%d'),
                    'end_date': None,  # Open-ended
                    'max_amount': 100.0,
                    'reason': 'Second limit (open)'
                }
            ])
            
            loader = DataLoader(str(self.data_dir))
            df = loader.load_bundle(self.ticker)
            
            # First limit period: 500
            for i in range(4, 10):
                date_str = self.dates[i].strftime('%Y-%m-%d')
                if date_str in df.index:
                    self.assertEqual(df.loc[date_str, 'daily_limit'], 500.0)
            
            # Gap between limits: inf
            for i in range(10, 14):
                date_str = self.dates[i].strftime('%Y-%m-%d')
                if date_str in df.index:
                    self.assertEqual(df.loc[date_str, 'daily_limit'], float('inf'))
            
            # Second limit (open-ended): 100
            for i in range(14, len(self.dates)):
                date_str = self.dates[i].strftime('%Y-%m-%d')
                if date_str in df.index:
                    self.assertEqual(df.loc[date_str, 'daily_limit'], 100.0)
        
        def test_open_ended_at_start_of_range(self):
            """Test open-ended limit that starts at the first date."""
            self._create_limit_events([{
                'start_date': self.dates[0].strftime('%Y-%m-%d'),
                'end_date': None,
                'max_amount': 50.0,
                'reason': 'Open from start'
            }])
            
            loader = DataLoader(str(self.data_dir))
            df = loader.load_bundle(self.ticker)
            
            # All dates should have the limit
            for date in df.index:
                self.assertEqual(df.loc[date, 'daily_limit'], 50.0)
        
        def test_no_limit_events_returns_all_inf(self):
            """Test that no limit events means unlimited."""
            # Create empty database
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            cursor.execute('''
                CREATE TABLE limit_events (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    ticker TEXT NOT NULL,
                    start_date DATE NOT NULL,
                    end_date DATE,
                    max_amount REAL NOT NULL,
                    reason TEXT
                )
            ''')
            conn.commit()
            conn.close()
            
            loader = DataLoader(str(self.data_dir))
            df = loader.load_bundle(self.ticker)
            
            # All dates should be unlimited
            self.assertTrue(all(df['daily_limit'] == float('inf')))
    
    
    if __name__ == '__main__':
        unittest.main()
    ```
    
    This test file covers:
    1. NULL end_date applying to all future dates
    2. Regular limits with end_date (regression test)
    3. Mixed open and closed limits
    4. Open-ended limit at start of range
    5. No limits (all inf)
  </action>
  <verify>
    Run: python -m pytest tests/test_open_ended_limits.py -v (or python tests/test_open_ended_limits.py)
  </verify>
  <done>
    - test_open_ended_limits.py created with 5+ test cases
    - Tests cover NULL end_date, mixed limits, edge cases
    - Uses temporary directories for isolation
    - All tests pass
  </done>
</task>

<task type="auto">
  <name>Task 2: Create database schema validation tests</name>
  <files>tests/test_database_schema.py</files>
  <action>
    Create a test file for database schema validation.
    
    ```python
    """
    Tests for database schema validation.
    
    Verifies that all tables have correct columns, types, and indexes.
    """
    
    import sys
    from pathlib import Path
    sys.path.insert(0, str(Path(__file__).parent.parent))
    
    import unittest
    import sqlite3
    import tempfile
    import json
    from pathlib import Path
    
    from src.data.generator import MockConfig, generate_mock_data
    from src.data.downloader import RealDataDownloader
    
    
    class TestDatabaseSchema(unittest.TestCase):
        """Test database schema for all tables."""
        
        def setUp(self):
            """Create temporary database."""
            self.temp_dir = tempfile.mkdtemp()
            self.db_path = Path(self.temp_dir) / 'fund_status.db'
        
        def tearDown(self):
            """Clean up."""
            import shutil
            shutil.rmtree(self.temp_dir)
        
        def _get_table_info(self, table_name):
            """Get column info for a table."""
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            cursor.execute(f"PRAGMA table_info({table_name})")
            columns = {row[1]: {'type': row[2], 'notnull': row[3], 'default': row[4]} 
                      for row in cursor.fetchall()}
            conn.close()
            return columns
        
        def _get_indexes(self, table_name):
            """Get indexes for a table."""
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            cursor.execute(f"PRAGMA index_list({table_name})")
            indexes = {row[1]: row} for row in cursor.fetchall()
            conn.close()
            return indexes
        
        def test_limit_events_schema(self):
            """Test limit_events table has correct schema."""
            # Create table using SQL similar to downloader/generators
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            cursor.execute('''
                CREATE TABLE limit_events (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    ticker TEXT NOT NULL,
                    start_date DATE NOT NULL,
                    end_date DATE,
                    max_amount REAL NOT NULL,
                    is_open_ended INTEGER GENERATED ALWAYS AS (
                        CASE WHEN end_date IS NULL THEN 1 ELSE 0 END
                    ) STORED,
                    source_announcement_ids TEXT,
                    reason TEXT
                )
            ''')
            conn.commit()
            conn.close()
            
            columns = self._get_table_info('limit_events')
            
            # Check required columns exist
            self.assertIn('id', columns)
            self.assertIn('ticker', columns)
            self.assertIn('start_date', columns)
            self.assertIn('end_date', columns)
            self.assertIn('max_amount', columns)
            self.assertIn('is_open_ended', columns)
            self.assertIn('source_announcement_ids', columns)
            self.assertIn('reason', columns)
            
            # Check nullability
            self.assertEqual(columns['ticker']['notnull'], 1)
            self.assertEqual(columns['start_date']['notnull'], 1)
            self.assertEqual(columns['end_date']['notnull'], 0)  # Nullable
            self.assertEqual(columns['max_amount']['notnull'], 1)
            
            # is_open_ended should be a generated column
            # SQLite stores generated columns differently - just verify it exists
        
        def test_announcement_parses_schema(self):
            """Test announcement_parses table has correct schema."""
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            cursor.execute('''
                CREATE TABLE announcement_parses (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    ticker TEXT NOT NULL,
                    announcement_date DATE NOT NULL,
                    pdf_filename TEXT NOT NULL,
                    parse_result TEXT,
                    parse_type TEXT,
                    confidence REAL,
                    processed INTEGER DEFAULT 0,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            conn.commit()
            conn.close()
            
            columns = self._get_table_info('announcement_parses')
            
            # Check all columns exist
            required = ['id', 'ticker', 'announcement_date', 'pdf_filename',
                       'parse_result', 'parse_type', 'confidence', 'processed', 'created_at']
            for col in required:
                self.assertIn(col, columns, f"Missing column: {col}")
            
            # Check defaults
            self.assertEqual(columns['processed']['default'], '0')
            self.assertIn('CURRENT_TIMESTAMP', str(columns['created_at']['default']))
        
        def test_limit_event_log_schema(self):
            """Test limit_event_log table has correct schema."""
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            cursor.execute('''
                CREATE TABLE limit_event_log (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    ticker TEXT NOT NULL,
                    operation TEXT NOT NULL,
                    old_start DATE,
                    old_end DATE,
                    new_start DATE,
                    new_end DATE,
                    triggered_by TEXT,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            conn.commit()
            conn.close()
            
            columns = self._get_table_info('limit_event_log')
            
            # Check all columns exist
            required = ['id', 'ticker', 'operation', 'old_start', 'old_end',
                       'new_start', 'new_end', 'triggered_by', 'created_at']
            for col in required:
                self.assertIn(col, columns, f"Missing column: {col}")
        
        def test_is_open_ended_computation(self):
            """Test that is_open_ended is correctly computed."""
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            cursor.execute('''
                CREATE TABLE limit_events (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    ticker TEXT NOT NULL,
                    start_date DATE NOT NULL,
                    end_date DATE,
                    max_amount REAL NOT NULL,
                    is_open_ended INTEGER GENERATED ALWAYS AS (
                        CASE WHEN end_date IS NULL THEN 1 ELSE 0 END
                    ) STORED,
                    source_announcement_ids TEXT,
                    reason TEXT
                )
            ''')
            
            # Insert test data
            cursor.execute('''
                INSERT INTO limit_events (ticker, start_date, end_date, max_amount, reason)
                VALUES (?, ?, ?, ?, ?)
            ''', ('TEST', '2024-01-01', '2024-01-15', 100, 'Closed limit'))
            
            cursor.execute('''
                INSERT INTO limit_events (ticker, start_date, end_date, max_amount, reason)
                VALUES (?, ?, ?, ?, ?)
            ''', ('TEST', '2024-02-01', None, 50, 'Open limit'))
            
            conn.commit()
            
            # Check computed values
            cursor.execute('SELECT end_date, is_open_ended FROM limit_events ORDER BY id')
            results = cursor.fetchall()
            
            # First row: has end_date, is_open_ended should be 0
            self.assertIsNotNone(results[0][0])
            self.assertEqual(results[0][1], 0)
            
            # Second row: no end_date, is_open_ended should be 1
            self.assertIsNone(results[1][0])
            self.assertEqual(results[1][1], 1)
            
            conn.close()
        
        def test_indexes_exist(self):
            """Test that expected indexes are created."""
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # Create tables with indexes
            cursor.execute('''
                CREATE TABLE announcement_parses (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    ticker TEXT NOT NULL,
                    announcement_date DATE NOT NULL,
                    pdf_filename TEXT NOT NULL,
                    parse_result TEXT,
                    parse_type TEXT,
                    confidence REAL,
                    processed INTEGER DEFAULT 0,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            cursor.execute('''
                CREATE INDEX idx_announcement_parses_ticker 
                ON announcement_parses(ticker)
            ''')
            cursor.execute('''
                CREATE INDEX idx_announcement_parses_processed 
                ON announcement_parses(processed)
            ''')
            
            conn.commit()
            
            # Check indexes exist
            cursor.execute("SELECT name FROM sqlite_master WHERE type='index'")
            index_names = {row[0] for row in cursor.fetchall()}
            
            self.assertIn('idx_announcement_parses_ticker', index_names)
            self.assertIn('idx_announcement_parses_processed', index_names)
            
            conn.close()
    
    
    if __name__ == '__main__':
        unittest.main()
    ```
  </action>
  <verify>
    Run: python -m pytest tests/test_database_schema.py -v
  </verify>
  <done>
    - test_database_schema.py created with schema validation tests
    - Tests cover all three tables
    - Tests verify is_open_ended computation
    - Tests verify indexes exist
  </done>
</task>

<task type="auto">
  <name>Task 3: Run all existing tests to verify no regressions</name>
  <files>tests/test_loader.py</files>
  <action>
    Run the existing test suite to ensure no regressions from the changes.
    
    Execute:
    ```bash
    # Run existing tests
    python tests/test_loader.py
    
    # If pytest is available
    python -m pytest tests/ -v --tb=short
    ```
    
    If tests fail due to schema changes, fix the issues:
    1. If test_loader.py expects specific column names, update expectations
    2. If tests insert data with missing new columns, update INSERT statements in tests
    3. Document any intentional breaking changes
    
    Pay special attention to:
    - `verify_limit_logic()` function which queries limit_events
    - Any hardcoded SQL that might need updating
    
    The test at line 72 does: `end_str = event.iloc[0]['end_date']` - this should still work even if end_date is NULL, but verify the comparison logic handles it.
  </action>
  <verify>
    All tests pass without errors
  </verify>
  <done>
    - test_loader.py runs successfully
    - No regressions from schema changes
    - All test assertions pass
  </done>
</task>

</tasks>

<verification>
After completing all tasks:
1. Run all test files to ensure complete coverage
2. Verify test output shows all tests passing
3. Check that edge cases are covered
</verification>

<success_criteria>
- test_open_ended_limits.py exists with comprehensive NULL handling tests
- test_database_schema.py exists with schema validation tests
- All new tests pass
- Existing tests (test_loader.py) still pass
- No regressions in functionality
</success_criteria>

<output>
After completion, create `.planning/phases/01-foundation/01-04-SUMMARY.md`
</output>
